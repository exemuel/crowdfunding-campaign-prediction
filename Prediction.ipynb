{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions of Crowdfunding Campaign Success with Machine Learning Approach\n",
    "\n",
    "Over the past century there has been a dramatic increase in crowdfunding project activity, which offers an alternative for both creators and backers to sell products and invest in creative businesses respectively. However, empirical analysis shows that only one-third of crowdfunding campaigns could meet their fundraising goal. The aim of this project is to develop a model that predicts the success of crowdfunding project with machine learning approach. The datasets are retrospectively collected from Web Robots, Kickstarter website, and Indiegogo website. The model could provide insights in pre-lunching stage and in early stage of fundraising.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Libraries](#libs)\n",
    "2. [Reader](#reads)\n",
    "3. [Analysis](#analysis)\n",
    "4. [Preparations](#prepares)\n",
    "5. [Selection](#selection)\n",
    "6. [Preprocessing](#preps)\n",
    "7. [Word Embeddings](#wembed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries <a class=\"anchor\" id=\"libs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import json\n",
    "\n",
    "# 3rd party libraries\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# custom libraries\n",
    "from src.reader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reader <a class=\"anchor\" id=\"reads\"></a>\n",
    "\n",
    "We combine dataset from [Web Robots](https://webrobots.io/kickstarter-datasets/) and [Our Scraper]( https://github.com/unedo08/kickstarter-scrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_json_file = \"dataset\\kickstarter-corpus.json\"\n",
    "path_kickstarter_csv = \"dataset\\kickstarter\"\n",
    "\n",
    "df_ks = read_json(path_json_file).merge(read_csv(path_kickstarter_csv), how=\"inner\", on=\"site\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check three rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(df_ks.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis  <a class=\"anchor\" id=\"analysis\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 45 columns (attributes) with 11637 rows of data.\n",
    "\n",
    "For text attributes _(temporary)_, we will use:\n",
    "- `story in campaign column`\n",
    "- `post comment`\n",
    "\n",
    "For meta attributes _(temporary)_, we will use:\n",
    "- `backers_count`\n",
    "- `usd_pledged`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparation <a class=\"anchor\" id=\"prepares\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc_ks = df_ks.copy()\n",
    "\n",
    "# create a new column from story key in campain \n",
    "dfc_ks[\"story\"] = [d.get(\"story\") for d in dfc_ks.campaign]\n",
    "\n",
    "# drop rows with empty story\n",
    "dfc_ks = dfc_ks[(dfc_ks.story != \"\") & (dfc_ks.story != \"<n/a>\")]\n",
    "\n",
    "# drop rows with empty comment\n",
    "dfc_ks = dfc_ks[(dfc_ks.comment != {}) & (dfc_ks.comment != \"<n/a>\")]\n",
    "dfc_ks = dfc_ks.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selection <a class=\"anchor\" id=\"selection\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Selection on Text Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# story as string and comment as list of string\n",
    "list_comments = []\n",
    "for i in dfc_ks.itertuples():\n",
    "    list_sub_comments = []\n",
    "    for j in i.comment:\n",
    "        list_sub_comments.append(i.comment[j][\"post_comment\"])\n",
    "    list_comments.append(list_sub_comments)\n",
    "df_text = pd.DataFrame(dfc_ks[[\"site\", \"story\"]])\n",
    "df_text[\"comment\"] = list_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Selection on Meta Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.DataFrame(dfc_ks[[\"backers_count\", \"usd_pledged\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocessing <a class=\"anchor\" id=\"preps\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenization(df_in):\n",
    "    try:\n",
    "        print(f\"Word Tokenization is in progress...\")\n",
    "        df_copy = df_in.copy()\n",
    "        df_copy[\"story\"] = df_copy[\"story\"].apply(lambda t: word_tokenize(t))\n",
    "        df_copy[\"comment\"] = [[word_tokenize(t) for t in i] for i in df_copy[\"comment\"]]\n",
    "        df_out = df_copy.copy()\n",
    "        print(f\"Word Tokenization is complete.\")\n",
    "        return df_out\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return df_in\n",
    "\n",
    "def lowercasing(df_in):\n",
    "    try:\n",
    "        print(f\"Lowercasing is in progress...\")\n",
    "        df_copy = df_in.copy()\n",
    "        df_copy[\"story\"] = df_copy[\"story\"].apply(lambda i: list(map(lambda t: t.lower(), i)))\n",
    "        df_copy[\"comment\"] = [[[t.lower() for t in j] for j in i] for i in df_copy[\"comment\"]]\n",
    "        df_out = df_copy\n",
    "        print(f\"Lowercasing is complete.\")\n",
    "        return df_out\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return df_in\n",
    "    \n",
    "def stopword_removal(df_in):\n",
    "    try:\n",
    "        print(f\"Stopword Removal is in progress...\")\n",
    "        # Porter M.F. (1980) An Algorithm for Suffix Stripping. Program, 14: 130-137.\n",
    "        stoplist = stopwords.words('english')       \n",
    "        df_copy = df_in.copy()\n",
    "        # exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "        df_copy[\"story\"] = df_copy[\"story\"].apply(lambda i: [t for t in i if t not in (stoplist)])\n",
    "        df_copy[\"comment\"] = [[[t for t in j if t not in (stoplist)] for j in i] for i in df_copy[\"comment\"]]\n",
    "        df_out = df_copy\n",
    "        print(f\"Stopword Removal is complete.\")\n",
    "        return df_out\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return df_in\n",
    "\n",
    "def stemming(df_in):\n",
    "    try:\n",
    "        print(f\"Stemming is in progress...\")\n",
    "        df_copy = df_in.copy()\n",
    "        ps = PorterStemmer()\n",
    "        df_copy[\"story\"] = df_copy[\"story\"].apply(lambda i: [ps.stem(t) for t in i])\n",
    "        df_copy[\"comment\"] = [[[ps.stem(t) for t in j] for j in i] for i in df_copy[\"comment\"]]\n",
    "        df_out = df_copy\n",
    "        print(f\"Stemming is complete.\")\n",
    "        return df_out\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return df_in\n",
    "\n",
    "def html_tag_removal(txt):\n",
    "    # regex pattern object of html bracket\n",
    "    bracket = re.compile(\"<.*?>\")\n",
    "    res = re.sub(bracket, \"\", txt)\n",
    "    return res\n",
    "\n",
    "def punctuation_removal(txt):\n",
    "    res = re.sub(r'[^\\w\\s]', '', txt)\n",
    "    return res\n",
    "\n",
    "def html_tag_and_punctuation_removal(df_in):\n",
    "    try:\n",
    "        print(f\"HTML Tag and Punctuation Removal is in progress...\")\n",
    "        df_copy = df_in.copy()\n",
    "        \n",
    "        # html tag removal\n",
    "        df_copy[\"story\"] = [list(filter(None, [html_tag_removal(t) for t in i])) for i in df_copy[\"story\"]]\n",
    "        df_copy[\"comment\"] = [[list(filter(None, [html_tag_removal(t) for t in j])) for j in i] for i in df_copy[\"comment\"]]\n",
    "        \n",
    "        # punctuation removal\n",
    "        df_copy[\"story\"] = [list(filter(None, [punctuation_removal(t) for t in i])) for i in df_copy[\"story\"]]\n",
    "        df_copy[\"comment\"] = [[list(filter(None, [punctuation_removal(t) for t in j])) for j in i] for i in df_copy[\"comment\"]]\n",
    "        \n",
    "        df_out = df_copy\n",
    "        print(f\"HTML Tag and Punctuation Removal is complete.\")\n",
    "        return df_out\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return df_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Text Attributes Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = word_tokenization(df_text)\n",
    "df_text = lowercasing(df_text)\n",
    "df_text = stopword_removal(df_text)\n",
    "df_text = stemming(df_text)\n",
    "df_text = html_tag_and_punctuation_removal(df_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Meta Attributes Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Word Embeddings <a class=\"anchor\" id=\"wembed\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "126fa1eadb53c9b2ae4bf68a75e7f1a01464bb27fcaf8e5a2d0703daa3413476"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
